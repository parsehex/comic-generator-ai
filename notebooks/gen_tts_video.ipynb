{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains two methods to generate a video by starting with a text input to read using TTS.\n",
    "\n",
    "The first method adds subtitles to the video that display 1+ line at a time. The second method adds word-synced captions to the video using a modified `autocaption` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes on where im trying to go with this\n",
    "# can provide:\n",
    "# url which will be extracted to get input text (optionally formatted using LLM)\n",
    "# file or text which will be used as input text\n",
    "# video url which will skip the text/TTS and adds subtitles to the video\n",
    "\n",
    "# so the process involves:\n",
    "\n",
    "# with TTS audio, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.utils import ensuredir, displayVideo, get_text_from_url\n",
    "from src.enums import ElevenLabsTTSModel, ElevenLabsTTSVoice\n",
    "from src.tools.tts import make_tts\n",
    "from src.tools.stt import create_transcript\n",
    "from src.video.moviepy import create_video_with_subtitles, create_video_from_audio\n",
    "\n",
    "# change the model and/or voice if desired\n",
    "# TODO support openai tts\n",
    "tts_model = ElevenLabsTTSModel.Multilingual_v2.value\n",
    "tts_voice = ElevenLabsTTSVoice.Brian.value  # TODO add more voices to enum\n",
    "\n",
    "# choose 1 of the below inputs\n",
    "input_text = \"\"\"\"\"\"\n",
    "input_file = ''\n",
    "input_url = 'http://example.com'\n",
    "reformat_url_text = False\n",
    "input_video = '' # TODO\n",
    "\n",
    "output_file = 'example.mp3'\n",
    "\n",
    "method = 'subtitle' # 'subtitle' or 'autocaption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "if not input_video:\n",
    "\tinput_type: Literal['text', 'file', 'url'] = 'text'\n",
    "\tinput_src = input_text\n",
    "\tif input_file:\n",
    "\t\tinput_type = 'file'\n",
    "\t\tinput_src = input_file\n",
    "\telif input_url:\n",
    "\t\tinput_type = 'url'\n",
    "\t\tinput_src = input_url\n",
    "\n",
    "\tif input_url:\n",
    "\t\tres = get_text_from_url(input_url)\n",
    "\t\tif reformat_url_text:\n",
    "\t\t\tfrom src.tools.format_tts import format_tts_text\n",
    "\t\t\tres = format_tts_text(res)\n",
    "\t\tprint('url text:\\n' + res)\n",
    "else:\n",
    "\timport ffmpeg\n",
    "\timport yt_dlp\n",
    "\tp = 'output/tmp-video/'\n",
    "\tensuredir(p)\n",
    "\tydl = yt_dlp.YoutubeDL({\n",
    "\t\t'outtmpl': f'{p}/%(id)s.%(ext)s',\n",
    "\t})\n",
    "\tydl.download([input_video])\n",
    "\tinput_video = ydl.prepare_filename(ydl.extract_info(input_video, download=False))\n",
    "\tassert isinstance(input_video, str)\n",
    "\t# convert to mp4\n",
    "\tp = input_video.split('.')[0]\n",
    "\tffmpeg.input(input_video).output(f'{p}.mp4').run(overwrite_output=True)\n",
    "\tinput_video = f'{p}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'subtitle':\n",
    "\tif input_video:\n",
    "\t\tmedia_path = input_video\n",
    "\telse:\n",
    "\t\tmedia_path = make_tts(input_src, input_type, output_file, model=tts_model, voice=tts_voice)\n",
    "\ttranscript_path = create_transcript(media_path)\n",
    "\n",
    "\tvideo_output_file = f\"{os.path.splitext(media_path)[0]}.mp4\"\n",
    "\tensuredir(video_output_file)\n",
    "\tcreate_video_with_subtitles(media_path, transcript_path, video_output_file, False, 1280, 720)\n",
    "\tprint(f'Video saved to {video_output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'autocaption':\n",
    "\tfrom autocaption.predict import VideoCaptioner\n",
    "\timport shutil\n",
    "\n",
    "\tif input_video:\n",
    "\t\tmedia_path = input_video\n",
    "\t\tvideo_output_file = f\"{os.path.splitext(media_path)[0]}-subtitled.mp4\"\n",
    "\telse:\n",
    "\t\t# generate tts + video with audio\n",
    "\t\tmedia_path = make_tts(input_src, input_type, output_file, model=tts_model, voice=tts_voice)\n",
    "\t\tvideo_output_file = f\"{os.path.splitext(media_path)[0]}.mp4\"\n",
    "\t\tfilename = os.path.basename(video_output_file)\n",
    "\t\tcreate_video_from_audio(media_path, video_output_file)\n",
    "\n",
    "\tvc = VideoCaptioner()\n",
    "\toutput_paths = vc.add_captions(media_path, kerning=-2)\n",
    "\to = output_paths[0]\n",
    "\tshutil.move(o, video_output_file)\n",
    "\n",
    "# for this, still generate the tts\n",
    "# create video with audio and no subtitles\n",
    "# pass tts video to vc\n",
    "# add audio back to output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_output_file:\n",
    "\tdisplayVideo(path=video_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# youtube video as input\n",
    "# add captions to video\n",
    "\n",
    "# video_input = 'test2.mp4'\n",
    "# vc = VideoCaptioner()\n",
    "# outputs = vc.add_captions(video_input, kerning=-2)\n",
    "# o = outputs[0]\n",
    "# shutil.move(o, 'test3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - save transcript as word-timestamp json instead of srt, construct and write to srt to control split points\n",
    "# - display paragraph(s) of text at a time on screen,\n",
    "#   highlight segments as they're spoken\n",
    "# - generate background image for the video\n",
    "\n",
    "# idea for an autonomous version\n",
    "# a script format that defines the video\n",
    "# - list info at the beginning (audio, background color, etc)\n",
    "# - each line after contains a timestamp and and action of some sort\n",
    "#   - display text\n",
    "#   - display image\n",
    "# an llm could output this script and the app generates the video from it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
